{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Arts Module 1: Coincidence, correlation, causation\n",
    "\n",
    "To prepare for this mission, first collect a week's worth of data on two quantifiable phenomena in your life, such as hours of sleep and typing rate. Collect the data with as little variation as possible to reduce confounds. \n",
    "\n",
    "For this example, we will randomly generate sleep data for 2 months from a normal distribution, with an average of 8 hours and a standard deviation of 2 hours. The next cell will update the tools that let us install libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the dummy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta  # This helps us create dates and calculate the difference between dates (delta)\n",
    "import random  # This is to generate random numbers\n",
    "import numpy as np  # This is to use logs\n",
    "\n",
    "d1 = date(2017, 5, 1)  # Our experiment start date\n",
    "d2 = date(2017, 7, 1)  # Our experiment end date\n",
    "\n",
    "# Get datetime objects for each day. This iteratively adds dates on to the first date, up till the second date.\n",
    "collection_dates = [d1 + timedelta(days=i) for i in range((d2 - d1).days + 1)]\n",
    "\n",
    "# Create list of days with generated sleep hours. We are choosing sleep hours randomly in a set range.\n",
    "sleep_hours = [random.normalvariate(8, 2) for i in range(len(collection_dates))]\n",
    "\n",
    "# Generate pullups for each day increasing the distribution logarithmically.\n",
    "pullups = 10  # start average of pullups\n",
    "num_pullups = []\n",
    "for i in range(len(collection_dates)):\n",
    "    num_pullups.append(int(random.normalvariate(pullups + np.log(i+1), .5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now import Python's data analysis library `pandas`. With `pandas`, we can read our data from a CSV (comma separated value) file that may have been exported from Excel or Google Sheets. Since we've generated our data here, we'll just assign the data directly into a data frame. We also import an external library for Python called Bokeh. This library contains powerful tools for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # A data analysis library\n",
    "import bokeh as bkeh \n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.palettes import brewer\n",
    "from bokeh.layouts import column\n",
    "from bokeh.io import show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "df= pd.DataFrame({'Hours of Sleep': sleep_hours,\n",
    "                    'Number of Pullups': num_pullups},\n",
    "                    index=collection_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've worked with any statistical software before, a `pandas` data frame likely functions very similarly. It is a Python object that works like a table. Let's look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df #In a notebook, if you simply put the name of a variable in a cell, it will get printed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It read in our data and assigned our observations to dates. `pandas` also provides an easy plotting method, simply `plot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # Python's plotting library\n",
    "import seaborn as sns  # Makes matplotlib prettier\n",
    "\n",
    "df['Hours of Sleep'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a good start! But our x-axis is all blended together. We'll have to add in \"parameters\" to tell `pandas` more specific details about how our chart should look. Let's first use `rot` to rotate the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Pullups'].plot(rot=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rot=30` rotated our x-axis labels by 30 degrees. Now it's legible. Try adding a `title` to your plot below. If you can't guess the name of the parameter, try looking at the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) for the `plot` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## CHALLENGE\n",
    "\n",
    "## SOLUTION\n",
    "df['Number of Pullups'].plot(rot=30, title='Number of Pullups in May and June')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now feel free to experiment with plotting the other data you've collected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how can we plot everything at once? Well that's actually easier, we just tell `pandas` to plot the whole dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try adding in parameters to clean this up. To change colors, look at the `colormap` parameters, possible options are [here](# https://matplotlib.org/examples/color/colormaps_reference.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## CHALLENGE\n",
    "\n",
    "\n",
    "## POSSIBLE SOLUTION\n",
    "df.plot(kind='line', rot=30, title='Sleep and # of Pullups', colormap=\"Accent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we make subplots for each variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHALLENGE\n",
    "\n",
    "## SOLUTION\n",
    "ax = df.plot(kind='line', rot=30, subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at dummy data that has a correlation. Try to see how the graphs are different from the uncorrelated ones above. We are first going to generate the sleep data in the same manner as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = date(2017, 5, 1)  # Our experiment start date\n",
    "d2 = date(2017, 7, 1)  # Our experiment end date\n",
    "\n",
    "collection_dates = [d1 + timedelta(days=i) for i in range((d2 - d1).days + 1)] \n",
    "sleep_hours = [random.normalvariate(8, 2) for i in range(len(collection_dates))] #Generating random sleep data similar to before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simulate correlated data, we are going to make our typing speed collection using a crude multiplication based on the sleeping data. Keep in mind that this is not how real correlated data is created! This is simply a shortcut for the purposes of the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "typing_speed = 40  # Average typing speed\n",
    "typing_speed_collection = []\n",
    "for i in range(len(collection_dates)):\n",
    "    typing_speed_collection.append((sleep_hours[i])/10 * random.normalvariate(40,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the same kinds of graphs as before, but see what they look like for correlated data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.DataFrame({'Hours of Sleep': sleep_hours,\n",
    "                    'Typing Speed': typing_speed_collection},\n",
    "                    index=collection_dates)\n",
    "df1.plot(kind='line', rot=30, subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the differences between the uncorrelated and correlated graphs! Notice how the correlated graphs follow a similar trend. As a bonus challenge, try creating similar plots for other sets of data. Also, feel free to play around with more kinds of data distributions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick aside, let us go over how to import real data to create those plots, since you will be bringing in your own data. Your data will be in some kind of a spreadsheet. Save that file as a .csv (comma seperate values) file. This will make it easy to manipulate using Python. All we need to do is convert that csv into a dataframe file. Then, we can use all the plotting functions that we just used. \n",
    "\n",
    "## Using your own data\n",
    "\n",
    "Try it out with your own file! Make up random data if you don't have a file already and export it to a CSV format. You can create a file like this using Google Sheets, Microsoft Excel, etc. Eventually, you will have your own real file of data that you can upload and analyze, if you don't have it already.\n",
    "\n",
    "To upload your data make sure you're in the directory with the green notebook:\n",
    "\n",
    "![image](img/upload.png)\n",
    "\n",
    "Click the \"Upload\" button and upload your CSV. You should see it appear in the directory:\n",
    "\n",
    "![image](img/uploaded.png)\n",
    "\n",
    "Now you put the name of your file in the cell below and delete the hash tags in front of the two bottom lines. Make sure to run the cell after your make the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "your_file = \"my-file-name.csv\" # Make sure that your desired csv is in the same folder as this notebook.\n",
    "#csv_df = pd.read_csv(your_file)  # delete the first hash tag of this line!\n",
    "#csv_df  # delete the first hastag of this line!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all you need to do to run the functions/visualizations from this notebook on the new data is replace the name of the fake data set dataframe variables with the name of your new data set dataframe variable (For example, csv_df replacing df/df1, etc.).\n",
    "\n",
    "Doing all this analysis with Python's built in libraries is awesome! \n",
    "\n",
    "Now let's look at how we can form similar plots using the Bokeh visualization library imported from earlier! In the next few cells, we use Bokeh's inbuilt plotting functions to create powerful graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime(x): #This function helps convert the x-axis values to dates to make plotting easier\n",
    "    return np.array(x, dtype=np.datetime64)\n",
    "\n",
    "a = figure(x_axis_type=\"datetime\", title=\"Hours of Sleep in May and June\")\n",
    "a.grid.grid_line_alpha = 0.7\n",
    "a.xaxis.axis_label = 'Date'\n",
    "a.yaxis.axis_label = 'Hours of Sleep'\n",
    "\n",
    "a.line(datetime(collection_dates), df['Hours of Sleep'], color='#0000FF', legend='Hours')\n",
    "a.legend.location = \"top_left\"\n",
    "\n",
    "show(a) #This opens up our plot in a new tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar fashion to before, we can plot both time series on one graph. We can use a similar process as the previous cell. However in this case, we just add an extra line for our other column of data. We also change the title of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.line(datetime(collection_dates), df['Number of Pullups'], color='#7FF000', legend=\"Pullups\")\n",
    "a.title.text = \"Sleep vs # of Pullups\"\n",
    "a.yaxis.axis_label = ''\n",
    "\n",
    "show(a) #You may get a red error message after you run this cell, but ignore it. As long as this plot opens in the new tab, you are fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us create a subplot like before! We use a similar process as the last two cells to create the two plots again. Then, we use the built in column function in Bokeh to put the two plots in an aligned vertical column to create nice subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = figure(x_axis_type=\"datetime\", title=\"Hours of Sleep in May and June\")\n",
    "c.grid.grid_line_alpha=0.7\n",
    "c.xaxis.axis_label = 'Date'\n",
    "c.yaxis.axis_label = 'Hours of Sleep'\n",
    "\n",
    "c.line(datetime(collection_dates), df['Hours of Sleep'], color='#0000FF', legend='Hours')\n",
    "c.legend.location = \"top_left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = figure(x_axis_type=\"datetime\", title=\"# of Pullups\")\n",
    "d.grid.grid_line_alpha=0.7\n",
    "d.xaxis.axis_label = 'Date'\n",
    "d.yaxis.axis_label = 'Pullups'\n",
    "\n",
    "d.line(datetime(collection_dates), df['Number of Pullups'], color='#7FF000', legend='Hours')\n",
    "d.legend.location = \"top_left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(column(c,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from our results, the Bokeh plots have a great deal of built in functionality! You are able to easily pan and box zoom on the created Bokeh plots. Additionally, saving to PNG with Bokeh is extremely easy! Simply click the save button. We will go over saving to PNG with the built-in Python libraries in the cells below.\n",
    "\n",
    "As a review, we have provided you with two unique ways to create powerful plots in Python! Experiment with both, and learn their pros and cons!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to PNG\n",
    "\n",
    "To save the figure, we have to assign it first to a variable, then we'll just call the `savefig` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.plot(kind='line', rot=30, title='Sleep vs. # of Pullups', colormap=\"Accent\")\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('sleep-vs-pullups.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. But when we look at the output, it's quite poor quality, and it's cutting off our x-axis labels! How can we fix this?\n",
    "\n",
    "**HINT:** Look at the `tight_layout` method and the `DPI` parameter [here](https://matplotlib.org/api/pyplot_api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHALLENGE\n",
    "\n",
    "\n",
    "## SOLUTION\n",
    "ax = df.plot(kind='line', rot=30, title='Sleep vs. # of Pullups', colormap=\"Accent\")\n",
    "fig = ax.get_figure()\n",
    "fig.tight_layout()  # makes PNG formatted better\n",
    "fig.savefig('sleep-vs-pullups.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got everything charted nicely, let's see if we can detect any relationships in our data.\n",
    "\n",
    "## Correlation\n",
    "\n",
    "One of the most common and basic measures of correlation in [Pearson's `r`](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), which is defined as:\n",
    "\n",
    "$$ r = \\frac{n (\\sum{xy})-(\\sum{x})(\\sum{y})}{\\sqrt{ [n \\sum{x^2}-(\\sum{x})^2 ][n \\sum{y^2}-(\\sum{y})^2 }]} $$\n",
    "\n",
    "where `x` and `y` are two variables.\n",
    "\n",
    "If we're looking at hours of sleep and pullups, we can calculate Pearson's `r` with the `scipy` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr  \n",
    "\n",
    "r1 = pearsonr(df['Number of Pullups'], df['Hours of Sleep'])\n",
    "r2 = pearsonr(df1['Typing Speed'], df1['Hours of Sleep'])\n",
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the [documentation](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html) for `pearsonr`, you'll see it is returning first `r`, or the correlation coefficient, and secondly a 2-tailed p-value.\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "In terms of correlation interpretation, the values calculated above come in handy. Pearson's r takes on a value between +1 and −1, where 1 is total positive linear correlation, 0 is no linear correlation, and −1 is total negative linear correlation. The p-value helps us see the statistical significance of our results. A p-value closer to 0 (less than .05) means that our data is more significant. If the p-value is greater than .05, it indicates our data is less signficant. Note the differences between the correlated and uncorrelated data. Namely, the R value is closer to one for the correlated data, and the p value is smaller. Keep in mind that our correlated data is a crude, dummy model, so the values may not be as strong as they would be in real correlated data.\n",
    "\n",
    "So it looks like here there is no correlation whatsoever between sleep and pullups. This make sense, because sleep never changed from the normal distribution, while pullups slowly logarithmically increased. Moreover, number of pullups, initially, is probably more related to training. You might get some progress at the begining, but will level off if nothing else changes (hence the logarithmic scale).\n",
    "\n",
    "Post the plot image, your correlation number, and your conclusion about the nature of your phenomena to the course assets. Review and discuss the observations of other students. Remeber that your or your peers data could be real or fake, and that your conclusion could be reasonable, humorous or lyrical. \n",
    "\n",
    "## Prediction\n",
    "\n",
    "If our pullup data wasn't randomly generated, we could also build a model to predict how many pullups we might get in the future. Let's try for the sake of demonstration.\n",
    "\n",
    "We'll first fit our pullups to a simple linear OLS model using `scipy` and the `curve_fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "# define linear OLS function\n",
    "def linear_func(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "# fit function to data\n",
    "popt, pcov = scipy.optimize.curve_fit(linear_func,  range(62),  df['Number of Pullups'])  # range for number of days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at `popt` gives us the optimized parameters for the defined function (`a`, and `b`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a new range we want to predict on, let's do 100 more days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = range(0,162)\n",
    "\n",
    "# plot collected data\n",
    "plt.plot(range(62), df['Number of Pullups'])\n",
    "\n",
    "# plot fitted curve\n",
    "plt.plot(x_new, linear_func(x_new, *popt), 'r-', label='fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to tell, but we can see that a linear model does not fit a logarithmic curve very well. Let's try defining a log function instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_func(x, a, b,c):\n",
    "    return a*np.log2(c+x)+b\n",
    "\n",
    "popt, pcov = scipy.optimize.curve_fit(log_func,  range(62),  df['Number of Pullups'])\n",
    "\n",
    "print(\"Optimized parameters: \", popt)\n",
    "print()\n",
    "\n",
    "plt.plot(range(62), df['Number of Pullups'])\n",
    "plt.plot(x_new, log_func(x_new, *popt), 'r-', label='fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks a little better, so if we continued for another 100 days, we'd hit a steady average of 14.5 pullups, not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Through this module, you were able to learn about coincidence, correlation, and causation in data science! These concepts are instrumental for data analysis and visualization.\n",
    "\n",
    "Please fill out the form below to offer us feedback on this notebook. Thanks!\n",
    "\n",
    "https://goo.gl/forms/ADY9TJU3TGKlllyT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
